[2024-06-27T22:33:19.423+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-27T22:33:19.433+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: ecomm_data_pipeline.generate_and_insert_data scheduled__2023-01-01T01:40:00+00:00 [queued]>
[2024-06-27T22:33:19.436+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: ecomm_data_pipeline.generate_and_insert_data scheduled__2023-01-01T01:40:00+00:00 [queued]>
[2024-06-27T22:33:19.436+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 2
[2024-06-27T22:33:19.441+0000] {taskinstance.py:2330} INFO - Executing <Task(PythonOperator): generate_and_insert_data> on 2023-01-01 01:40:00+00:00
[2024-06-27T22:33:19.443+0000] {standard_task_runner.py:63} INFO - Started process 323 to run task
[2024-06-27T22:33:19.444+0000] {standard_task_runner.py:90} INFO - Running: ['airflow', 'tasks', 'run', 'ecomm_data_pipeline', 'generate_and_insert_data', 'scheduled__2023-01-01T01:40:00+00:00', '--job-id', '22', '--raw', '--subdir', 'DAGS_FOLDER/ecomm_dag.py', '--cfg-path', '/tmp/tmpxvu7cpdm']
[2024-06-27T22:33:19.444+0000] {standard_task_runner.py:91} INFO - Job 22: Subtask generate_and_insert_data
[2024-06-27T22:33:19.462+0000] {task_command.py:426} INFO - Running <TaskInstance: ecomm_data_pipeline.generate_and_insert_data scheduled__2023-01-01T01:40:00+00:00 [running]> on host 9174587f6b1d
[2024-06-27T22:33:19.492+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='ecomm_data_pipeline' AIRFLOW_CTX_TASK_ID='generate_and_insert_data' AIRFLOW_CTX_EXECUTION_DATE='2023-01-01T01:40:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2023-01-01T01:40:00+00:00'
[2024-06-27T22:33:19.492+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-27T22:33:19.526+0000] {logging_mixin.py:188} INFO - Error in generate_and_insert_data: Command '['python3', './generator/ecomm_generator.py']' returned non-zero exit status 2.
[2024-06-27T22:33:19.527+0000] {python.py:237} INFO - Done. Returned value was: None
[2024-06-27T22:33:19.527+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-27T22:33:19.532+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=ecomm_data_pipeline, task_id=generate_and_insert_data, run_id=scheduled__2023-01-01T01:40:00+00:00, execution_date=20230101T014000, start_date=20240627T223319, end_date=20240627T223319
[2024-06-27T22:33:19.543+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-27T22:33:19.550+0000] {taskinstance.py:3503} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-06-27T22:33:19.550+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-27T22:52:09.608+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-27T22:52:09.621+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: ecomm_data_pipeline.generate_and_insert_data scheduled__2023-01-01T01:40:00+00:00 [queued]>
[2024-06-27T22:52:09.624+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: ecomm_data_pipeline.generate_and_insert_data scheduled__2023-01-01T01:40:00+00:00 [queued]>
[2024-06-27T22:52:09.625+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 2
[2024-06-27T22:52:09.630+0000] {taskinstance.py:2330} INFO - Executing <Task(PythonOperator): generate_and_insert_data> on 2023-01-01 01:40:00+00:00
[2024-06-27T22:52:09.631+0000] {standard_task_runner.py:63} INFO - Started process 323 to run task
[2024-06-27T22:52:09.633+0000] {standard_task_runner.py:90} INFO - Running: ['airflow', 'tasks', 'run', 'ecomm_data_pipeline', 'generate_and_insert_data', 'scheduled__2023-01-01T01:40:00+00:00', '--job-id', '22', '--raw', '--subdir', 'DAGS_FOLDER/ecomm_dag.py', '--cfg-path', '/tmp/tmp595_vfzj']
[2024-06-27T22:52:09.634+0000] {standard_task_runner.py:91} INFO - Job 22: Subtask generate_and_insert_data
[2024-06-27T22:52:09.659+0000] {task_command.py:426} INFO - Running <TaskInstance: ecomm_data_pipeline.generate_and_insert_data scheduled__2023-01-01T01:40:00+00:00 [running]> on host a70edf9d8581
[2024-06-27T22:52:09.703+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='ecomm_data_pipeline' AIRFLOW_CTX_TASK_ID='generate_and_insert_data' AIRFLOW_CTX_EXECUTION_DATE='2023-01-01T01:40:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2023-01-01T01:40:00+00:00'
[2024-06-27T22:52:09.703+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-27T22:52:09.743+0000] {logging_mixin.py:188} INFO - Error in generate_and_insert_data: Command '['python3', './generator/ecomm_generator.py']' returned non-zero exit status 2.
[2024-06-27T22:52:09.743+0000] {logging_mixin.py:188} INFO - stdout: 
[2024-06-27T22:52:09.744+0000] {logging_mixin.py:188} INFO - stderr: python3: can't open file '/opt/airflow/./generator/ecomm_generator.py': [Errno 2] No such file or directory
[2024-06-27T22:52:09.744+0000] {python.py:237} INFO - Done. Returned value was: None
[2024-06-27T22:52:09.744+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-27T22:52:09.749+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=ecomm_data_pipeline, task_id=generate_and_insert_data, run_id=scheduled__2023-01-01T01:40:00+00:00, execution_date=20230101T014000, start_date=20240627T225209, end_date=20240627T225209
[2024-06-27T22:52:09.774+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-27T22:52:09.783+0000] {taskinstance.py:3503} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-06-27T22:52:09.784+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-27T22:59:53.137+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-27T22:59:53.148+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: ecomm_data_pipeline.generate_and_insert_data scheduled__2023-01-01T01:40:00+00:00 [queued]>
[2024-06-27T22:59:53.151+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: ecomm_data_pipeline.generate_and_insert_data scheduled__2023-01-01T01:40:00+00:00 [queued]>
[2024-06-27T22:59:53.151+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 2
[2024-06-27T22:59:53.156+0000] {taskinstance.py:2330} INFO - Executing <Task(PythonOperator): generate_and_insert_data> on 2023-01-01 01:40:00+00:00
[2024-06-27T22:59:53.157+0000] {standard_task_runner.py:63} INFO - Started process 323 to run task
[2024-06-27T22:59:53.158+0000] {standard_task_runner.py:90} INFO - Running: ['airflow', 'tasks', 'run', 'ecomm_data_pipeline', 'generate_and_insert_data', 'scheduled__2023-01-01T01:40:00+00:00', '--job-id', '22', '--raw', '--subdir', 'DAGS_FOLDER/ecomm_dag.py', '--cfg-path', '/tmp/tmpge2q86zt']
[2024-06-27T22:59:53.159+0000] {standard_task_runner.py:91} INFO - Job 22: Subtask generate_and_insert_data
[2024-06-27T22:59:53.177+0000] {task_command.py:426} INFO - Running <TaskInstance: ecomm_data_pipeline.generate_and_insert_data scheduled__2023-01-01T01:40:00+00:00 [running]> on host 5cc71d4b298c
[2024-06-27T22:59:53.208+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='ecomm_data_pipeline' AIRFLOW_CTX_TASK_ID='generate_and_insert_data' AIRFLOW_CTX_EXECUTION_DATE='2023-01-01T01:40:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2023-01-01T01:40:00+00:00'
[2024-06-27T22:59:53.208+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-27T22:59:53.267+0000] {logging_mixin.py:188} INFO - Error in generate_and_insert_data: Command '['python3', '/opt/airflow/generator/ecomm_generator.py']' returned non-zero exit status 1.
[2024-06-27T22:59:53.267+0000] {logging_mixin.py:188} INFO - stdout: 
[2024-06-27T22:59:53.267+0000] {logging_mixin.py:188} INFO - stderr: Traceback (most recent call last):
  File "/opt/airflow/generator/ecomm_generator.py", line 4, in <module>
    from faker import Faker
ModuleNotFoundError: No module named 'faker'
[2024-06-27T22:59:53.267+0000] {python.py:237} INFO - Done. Returned value was: None
[2024-06-27T22:59:53.267+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-27T22:59:53.272+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=ecomm_data_pipeline, task_id=generate_and_insert_data, run_id=scheduled__2023-01-01T01:40:00+00:00, execution_date=20230101T014000, start_date=20240627T225953, end_date=20240627T225953
[2024-06-27T22:59:53.301+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-27T22:59:53.308+0000] {taskinstance.py:3503} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-06-27T22:59:53.308+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-27T23:09:32.316+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-27T23:09:32.327+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: ecomm_data_pipeline.generate_and_insert_data scheduled__2023-01-01T01:40:00+00:00 [queued]>
[2024-06-27T23:09:32.329+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: ecomm_data_pipeline.generate_and_insert_data scheduled__2023-01-01T01:40:00+00:00 [queued]>
[2024-06-27T23:09:32.330+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 2
[2024-06-27T23:09:32.334+0000] {taskinstance.py:2330} INFO - Executing <Task(PythonOperator): generate_and_insert_data> on 2023-01-01 01:40:00+00:00
[2024-06-27T23:09:32.336+0000] {standard_task_runner.py:63} INFO - Started process 323 to run task
[2024-06-27T23:09:32.337+0000] {standard_task_runner.py:90} INFO - Running: ['airflow', 'tasks', 'run', 'ecomm_data_pipeline', 'generate_and_insert_data', 'scheduled__2023-01-01T01:40:00+00:00', '--job-id', '22', '--raw', '--subdir', 'DAGS_FOLDER/ecomm_dag.py', '--cfg-path', '/tmp/tmpzisy68_0']
[2024-06-27T23:09:32.338+0000] {standard_task_runner.py:91} INFO - Job 22: Subtask generate_and_insert_data
[2024-06-27T23:09:32.356+0000] {task_command.py:426} INFO - Running <TaskInstance: ecomm_data_pipeline.generate_and_insert_data scheduled__2023-01-01T01:40:00+00:00 [running]> on host 7147f8a4dc9f
[2024-06-27T23:09:32.385+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='ecomm_data_pipeline' AIRFLOW_CTX_TASK_ID='generate_and_insert_data' AIRFLOW_CTX_EXECUTION_DATE='2023-01-01T01:40:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2023-01-01T01:40:00+00:00'
[2024-06-27T23:09:32.386+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-27T23:09:32.444+0000] {logging_mixin.py:188} INFO - Error in generate_and_insert_data: Command '['python3', '/opt/airflow/generator/ecomm_generator.py']' returned non-zero exit status 1.
[2024-06-27T23:09:32.445+0000] {logging_mixin.py:188} INFO - stdout: 
[2024-06-27T23:09:32.445+0000] {logging_mixin.py:188} INFO - stderr: Traceback (most recent call last):
  File "/opt/airflow/generator/ecomm_generator.py", line 4, in <module>
    from faker import Faker
ModuleNotFoundError: No module named 'faker'
[2024-06-27T23:09:32.445+0000] {python.py:237} INFO - Done. Returned value was: None
[2024-06-27T23:09:32.445+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-27T23:09:32.451+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=ecomm_data_pipeline, task_id=generate_and_insert_data, run_id=scheduled__2023-01-01T01:40:00+00:00, execution_date=20230101T014000, start_date=20240627T230932, end_date=20240627T230932
[2024-06-27T23:09:32.474+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-27T23:09:32.481+0000] {taskinstance.py:3503} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-06-27T23:09:32.482+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-27T23:13:10.563+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-27T23:13:10.575+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: ecomm_data_pipeline.generate_and_insert_data scheduled__2023-01-01T01:40:00+00:00 [queued]>
[2024-06-27T23:13:10.577+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: ecomm_data_pipeline.generate_and_insert_data scheduled__2023-01-01T01:40:00+00:00 [queued]>
[2024-06-27T23:13:10.578+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 2
[2024-06-27T23:13:10.582+0000] {taskinstance.py:2330} INFO - Executing <Task(PythonOperator): generate_and_insert_data> on 2023-01-01 01:40:00+00:00
[2024-06-27T23:13:10.584+0000] {standard_task_runner.py:63} INFO - Started process 323 to run task
[2024-06-27T23:13:10.585+0000] {standard_task_runner.py:90} INFO - Running: ['airflow', 'tasks', 'run', 'ecomm_data_pipeline', 'generate_and_insert_data', 'scheduled__2023-01-01T01:40:00+00:00', '--job-id', '22', '--raw', '--subdir', 'DAGS_FOLDER/ecomm_dag.py', '--cfg-path', '/tmp/tmpleg05170']
[2024-06-27T23:13:10.586+0000] {standard_task_runner.py:91} INFO - Job 22: Subtask generate_and_insert_data
[2024-06-27T23:13:10.603+0000] {task_command.py:426} INFO - Running <TaskInstance: ecomm_data_pipeline.generate_and_insert_data scheduled__2023-01-01T01:40:00+00:00 [running]> on host 4bd55eb76a74
[2024-06-27T23:13:10.634+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='ecomm_data_pipeline' AIRFLOW_CTX_TASK_ID='generate_and_insert_data' AIRFLOW_CTX_EXECUTION_DATE='2023-01-01T01:40:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2023-01-01T01:40:00+00:00'
[2024-06-27T23:13:10.635+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-27T23:13:10.694+0000] {logging_mixin.py:188} INFO - Error in generate_and_insert_data: Command '['python3', '/opt/airflow/generator/ecomm_generator.py']' returned non-zero exit status 1.
[2024-06-27T23:13:10.694+0000] {logging_mixin.py:188} INFO - stdout: 
[2024-06-27T23:13:10.694+0000] {logging_mixin.py:188} INFO - stderr: Traceback (most recent call last):
  File "/opt/airflow/generator/ecomm_generator.py", line 4, in <module>
    from faker import Faker
ModuleNotFoundError: No module named 'faker'
[2024-06-27T23:13:10.694+0000] {python.py:237} INFO - Done. Returned value was: None
[2024-06-27T23:13:10.695+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-27T23:13:10.700+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=ecomm_data_pipeline, task_id=generate_and_insert_data, run_id=scheduled__2023-01-01T01:40:00+00:00, execution_date=20230101T014000, start_date=20240627T231310, end_date=20240627T231310
[2024-06-27T23:13:10.728+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-27T23:13:10.735+0000] {taskinstance.py:3503} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-06-27T23:13:10.736+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-27T23:19:06.185+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-27T23:19:06.197+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: ecomm_data_pipeline.generate_and_insert_data scheduled__2023-01-01T01:40:00+00:00 [queued]>
[2024-06-27T23:19:06.200+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: ecomm_data_pipeline.generate_and_insert_data scheduled__2023-01-01T01:40:00+00:00 [queued]>
[2024-06-27T23:19:06.200+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 2
[2024-06-27T23:19:06.205+0000] {taskinstance.py:2330} INFO - Executing <Task(PythonOperator): generate_and_insert_data> on 2023-01-01 01:40:00+00:00
[2024-06-27T23:19:06.207+0000] {standard_task_runner.py:63} INFO - Started process 323 to run task
[2024-06-27T23:19:06.208+0000] {standard_task_runner.py:90} INFO - Running: ['airflow', 'tasks', 'run', 'ecomm_data_pipeline', 'generate_and_insert_data', 'scheduled__2023-01-01T01:40:00+00:00', '--job-id', '22', '--raw', '--subdir', 'DAGS_FOLDER/ecomm_dag.py', '--cfg-path', '/tmp/tmp0mfym96o']
[2024-06-27T23:19:06.209+0000] {standard_task_runner.py:91} INFO - Job 22: Subtask generate_and_insert_data
[2024-06-27T23:19:06.229+0000] {task_command.py:426} INFO - Running <TaskInstance: ecomm_data_pipeline.generate_and_insert_data scheduled__2023-01-01T01:40:00+00:00 [running]> on host 73964f870a02
[2024-06-27T23:19:06.267+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='ecomm_data_pipeline' AIRFLOW_CTX_TASK_ID='generate_and_insert_data' AIRFLOW_CTX_EXECUTION_DATE='2023-01-01T01:40:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2023-01-01T01:40:00+00:00'
[2024-06-27T23:19:06.267+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-27T23:19:06.332+0000] {logging_mixin.py:188} INFO - Error in generate_and_insert_data: Command '['python3', '/opt/airflow/generator/ecomm_generator.py']' returned non-zero exit status 1.
[2024-06-27T23:19:06.333+0000] {logging_mixin.py:188} INFO - stdout: 
[2024-06-27T23:19:06.333+0000] {logging_mixin.py:188} INFO - stderr: Traceback (most recent call last):
  File "/opt/airflow/generator/ecomm_generator.py", line 4, in <module>
    from faker import Faker
ModuleNotFoundError: No module named 'faker'
[2024-06-27T23:19:06.333+0000] {python.py:237} INFO - Done. Returned value was: None
[2024-06-27T23:19:06.333+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-27T23:19:06.338+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=ecomm_data_pipeline, task_id=generate_and_insert_data, run_id=scheduled__2023-01-01T01:40:00+00:00, execution_date=20230101T014000, start_date=20240627T231906, end_date=20240627T231906
[2024-06-27T23:19:06.348+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-27T23:19:06.355+0000] {taskinstance.py:3503} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-06-27T23:19:06.355+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-28T18:13:27.373+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-28T18:13:27.383+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: ecomm_data_pipeline.generate_and_insert_data scheduled__2023-01-01T01:40:00+00:00 [queued]>
[2024-06-28T18:13:27.385+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: ecomm_data_pipeline.generate_and_insert_data scheduled__2023-01-01T01:40:00+00:00 [queued]>
[2024-06-28T18:13:27.385+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 2
[2024-06-28T18:13:27.390+0000] {taskinstance.py:2330} INFO - Executing <Task(PythonOperator): generate_and_insert_data> on 2023-01-01 01:40:00+00:00
[2024-06-28T18:13:27.392+0000] {standard_task_runner.py:63} INFO - Started process 323 to run task
[2024-06-28T18:13:27.393+0000] {standard_task_runner.py:90} INFO - Running: ['airflow', 'tasks', 'run', 'ecomm_data_pipeline', 'generate_and_insert_data', 'scheduled__2023-01-01T01:40:00+00:00', '--job-id', '22', '--raw', '--subdir', 'DAGS_FOLDER/ecomm_dag.py', '--cfg-path', '/tmp/tmpqq59tiqg']
[2024-06-28T18:13:27.394+0000] {standard_task_runner.py:91} INFO - Job 22: Subtask generate_and_insert_data
[2024-06-28T18:13:27.410+0000] {task_command.py:426} INFO - Running <TaskInstance: ecomm_data_pipeline.generate_and_insert_data scheduled__2023-01-01T01:40:00+00:00 [running]> on host 08cefd381a1f
[2024-06-28T18:13:27.438+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='ecomm_data_pipeline' AIRFLOW_CTX_TASK_ID='generate_and_insert_data' AIRFLOW_CTX_EXECUTION_DATE='2023-01-01T01:40:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2023-01-01T01:40:00+00:00'
[2024-06-28T18:13:27.438+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-28T18:13:27.492+0000] {logging_mixin.py:188} INFO - Error in generate_and_insert_data: Command '['python3', '/opt/airflow/generator/ecomm_generator.py']' returned non-zero exit status 1.
[2024-06-28T18:13:27.492+0000] {logging_mixin.py:188} INFO - stdout: 
[2024-06-28T18:13:27.493+0000] {logging_mixin.py:188} INFO - stderr: Traceback (most recent call last):
  File "/opt/airflow/generator/ecomm_generator.py", line 4, in <module>
    from faker import Faker
ModuleNotFoundError: No module named 'faker'
[2024-06-28T18:13:27.493+0000] {python.py:237} INFO - Done. Returned value was: None
[2024-06-28T18:13:27.493+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-28T18:13:27.498+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=ecomm_data_pipeline, task_id=generate_and_insert_data, run_id=scheduled__2023-01-01T01:40:00+00:00, execution_date=20230101T014000, start_date=20240628T181327, end_date=20240628T181327
[2024-06-28T18:13:27.541+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-28T18:13:27.547+0000] {taskinstance.py:3503} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-06-28T18:13:27.548+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-28T18:20:42.437+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-28T18:20:42.448+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: ecomm_data_pipeline.generate_and_insert_data scheduled__2023-01-01T01:40:00+00:00 [queued]>
[2024-06-28T18:20:42.451+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: ecomm_data_pipeline.generate_and_insert_data scheduled__2023-01-01T01:40:00+00:00 [queued]>
[2024-06-28T18:20:42.451+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 2
[2024-06-28T18:20:42.456+0000] {taskinstance.py:2330} INFO - Executing <Task(PythonOperator): generate_and_insert_data> on 2023-01-01 01:40:00+00:00
[2024-06-28T18:20:42.457+0000] {standard_task_runner.py:63} INFO - Started process 323 to run task
[2024-06-28T18:20:42.458+0000] {standard_task_runner.py:90} INFO - Running: ['airflow', 'tasks', 'run', 'ecomm_data_pipeline', 'generate_and_insert_data', 'scheduled__2023-01-01T01:40:00+00:00', '--job-id', '22', '--raw', '--subdir', 'DAGS_FOLDER/ecomm_dag.py', '--cfg-path', '/tmp/tmpkk1lclj_']
[2024-06-28T18:20:42.459+0000] {standard_task_runner.py:91} INFO - Job 22: Subtask generate_and_insert_data
[2024-06-28T18:20:42.477+0000] {task_command.py:426} INFO - Running <TaskInstance: ecomm_data_pipeline.generate_and_insert_data scheduled__2023-01-01T01:40:00+00:00 [running]> on host 6570e5857071
[2024-06-28T18:20:42.507+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='ecomm_data_pipeline' AIRFLOW_CTX_TASK_ID='generate_and_insert_data' AIRFLOW_CTX_EXECUTION_DATE='2023-01-01T01:40:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2023-01-01T01:40:00+00:00'
[2024-06-28T18:20:42.508+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-28T18:20:42.567+0000] {logging_mixin.py:188} INFO - Error in generate_and_insert_data: Command '['python3', '/opt/airflow/generator/ecomm_generator.py']' returned non-zero exit status 1.
[2024-06-28T18:20:42.568+0000] {logging_mixin.py:188} INFO - stdout: 
[2024-06-28T18:20:42.568+0000] {logging_mixin.py:188} INFO - stderr: Traceback (most recent call last):
  File "/opt/airflow/generator/ecomm_generator.py", line 4, in <module>
    from faker import Faker
ModuleNotFoundError: No module named 'faker'
[2024-06-28T18:20:42.568+0000] {python.py:237} INFO - Done. Returned value was: None
[2024-06-28T18:20:42.568+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-28T18:20:42.573+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=ecomm_data_pipeline, task_id=generate_and_insert_data, run_id=scheduled__2023-01-01T01:40:00+00:00, execution_date=20230101T014000, start_date=20240628T182042, end_date=20240628T182042
[2024-06-28T18:20:42.598+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-28T18:20:42.605+0000] {taskinstance.py:3503} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-06-28T18:20:42.605+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-28T18:30:44.315+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-28T18:30:44.326+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: ecomm_data_pipeline.generate_and_insert_data scheduled__2023-01-01T01:40:00+00:00 [queued]>
[2024-06-28T18:30:44.329+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: ecomm_data_pipeline.generate_and_insert_data scheduled__2023-01-01T01:40:00+00:00 [queued]>
[2024-06-28T18:30:44.329+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 2
[2024-06-28T18:30:44.334+0000] {taskinstance.py:2330} INFO - Executing <Task(PythonOperator): generate_and_insert_data> on 2023-01-01 01:40:00+00:00
[2024-06-28T18:30:44.335+0000] {standard_task_runner.py:63} INFO - Started process 323 to run task
[2024-06-28T18:30:44.336+0000] {standard_task_runner.py:90} INFO - Running: ['airflow', 'tasks', 'run', 'ecomm_data_pipeline', 'generate_and_insert_data', 'scheduled__2023-01-01T01:40:00+00:00', '--job-id', '22', '--raw', '--subdir', 'DAGS_FOLDER/ecomm_dag.py', '--cfg-path', '/tmp/tmp92kgc8w_']
[2024-06-28T18:30:44.337+0000] {standard_task_runner.py:91} INFO - Job 22: Subtask generate_and_insert_data
[2024-06-28T18:30:44.354+0000] {task_command.py:426} INFO - Running <TaskInstance: ecomm_data_pipeline.generate_and_insert_data scheduled__2023-01-01T01:40:00+00:00 [running]> on host 50bf780463b8
[2024-06-28T18:30:44.386+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='ecomm_data_pipeline' AIRFLOW_CTX_TASK_ID='generate_and_insert_data' AIRFLOW_CTX_EXECUTION_DATE='2023-01-01T01:40:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2023-01-01T01:40:00+00:00'
[2024-06-28T18:30:44.386+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-28T18:30:44.446+0000] {logging_mixin.py:188} INFO - Error in generate_and_insert_data: Command '['python3', '/opt/airflow/generator/ecomm_generator.py']' returned non-zero exit status 1.
[2024-06-28T18:30:44.446+0000] {logging_mixin.py:188} INFO - stdout: 
[2024-06-28T18:30:44.447+0000] {logging_mixin.py:188} INFO - stderr: Traceback (most recent call last):
  File "/opt/airflow/generator/ecomm_generator.py", line 4, in <module>
    from faker import Faker
ModuleNotFoundError: No module named 'faker'
[2024-06-28T18:30:44.447+0000] {python.py:237} INFO - Done. Returned value was: None
[2024-06-28T18:30:44.447+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-28T18:30:44.453+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=ecomm_data_pipeline, task_id=generate_and_insert_data, run_id=scheduled__2023-01-01T01:40:00+00:00, execution_date=20230101T014000, start_date=20240628T183044, end_date=20240628T183044
[2024-06-28T18:30:44.475+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-28T18:30:44.482+0000] {taskinstance.py:3503} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-06-28T18:30:44.483+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-28T22:13:54.264+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-28T22:13:54.275+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: ecomm_data_pipeline.generate_and_insert_data scheduled__2023-01-01T01:40:00+00:00 [queued]>
[2024-06-28T22:13:54.278+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: ecomm_data_pipeline.generate_and_insert_data scheduled__2023-01-01T01:40:00+00:00 [queued]>
[2024-06-28T22:13:54.278+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 2
[2024-06-28T22:13:54.283+0000] {taskinstance.py:2330} INFO - Executing <Task(PythonOperator): generate_and_insert_data> on 2023-01-01 01:40:00+00:00
[2024-06-28T22:13:54.284+0000] {standard_task_runner.py:63} INFO - Started process 323 to run task
[2024-06-28T22:13:54.285+0000] {standard_task_runner.py:90} INFO - Running: ['airflow', 'tasks', 'run', 'ecomm_data_pipeline', 'generate_and_insert_data', 'scheduled__2023-01-01T01:40:00+00:00', '--job-id', '22', '--raw', '--subdir', 'DAGS_FOLDER/ecomm_dag.py', '--cfg-path', '/tmp/tmptxdge5fk']
[2024-06-28T22:13:54.286+0000] {standard_task_runner.py:91} INFO - Job 22: Subtask generate_and_insert_data
[2024-06-28T22:13:54.304+0000] {task_command.py:426} INFO - Running <TaskInstance: ecomm_data_pipeline.generate_and_insert_data scheduled__2023-01-01T01:40:00+00:00 [running]> on host 619125b6796e
[2024-06-28T22:13:54.334+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='ecomm_data_pipeline' AIRFLOW_CTX_TASK_ID='generate_and_insert_data' AIRFLOW_CTX_EXECUTION_DATE='2023-01-01T01:40:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2023-01-01T01:40:00+00:00'
[2024-06-28T22:13:54.335+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-28T22:13:54.394+0000] {logging_mixin.py:188} INFO - Error in generate_and_insert_data: Command '['python3', '/opt/airflow/generator/ecomm_generator.py']' returned non-zero exit status 1.
[2024-06-28T22:13:54.395+0000] {logging_mixin.py:188} INFO - stdout: 
[2024-06-28T22:13:54.395+0000] {logging_mixin.py:188} INFO - stderr: Traceback (most recent call last):
  File "/opt/airflow/generator/ecomm_generator.py", line 4, in <module>
    from faker import Faker
ModuleNotFoundError: No module named 'faker'
[2024-06-28T22:13:54.395+0000] {python.py:237} INFO - Done. Returned value was: None
[2024-06-28T22:13:54.395+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-28T22:13:54.401+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=ecomm_data_pipeline, task_id=generate_and_insert_data, run_id=scheduled__2023-01-01T01:40:00+00:00, execution_date=20230101T014000, start_date=20240628T221354, end_date=20240628T221354
[2024-06-28T22:13:54.432+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-28T22:13:54.439+0000] {taskinstance.py:3503} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-06-28T22:13:54.440+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-29T21:36:55.075+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-29T21:36:55.085+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: ecomm_data_pipeline.generate_and_insert_data scheduled__2023-01-01T01:40:00+00:00 [queued]>
[2024-06-29T21:36:55.087+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: ecomm_data_pipeline.generate_and_insert_data scheduled__2023-01-01T01:40:00+00:00 [queued]>
[2024-06-29T21:36:55.088+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 2
[2024-06-29T21:36:55.092+0000] {taskinstance.py:2330} INFO - Executing <Task(PythonOperator): generate_and_insert_data> on 2023-01-01 01:40:00+00:00
[2024-06-29T21:36:55.094+0000] {standard_task_runner.py:63} INFO - Started process 181 to run task
[2024-06-29T21:36:55.095+0000] {standard_task_runner.py:90} INFO - Running: ['airflow', 'tasks', 'run', 'ecomm_data_pipeline', 'generate_and_insert_data', 'scheduled__2023-01-01T01:40:00+00:00', '--job-id', '12', '--raw', '--subdir', 'DAGS_FOLDER/ecomm_dag.py', '--cfg-path', '/tmp/tmpjkedp8wg']
[2024-06-29T21:36:55.095+0000] {standard_task_runner.py:91} INFO - Job 12: Subtask generate_and_insert_data
[2024-06-29T21:36:55.112+0000] {task_command.py:426} INFO - Running <TaskInstance: ecomm_data_pipeline.generate_and_insert_data scheduled__2023-01-01T01:40:00+00:00 [running]> on host afcb6fbf9265
[2024-06-29T21:36:55.139+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='ecomm_data_pipeline' AIRFLOW_CTX_TASK_ID='generate_and_insert_data' AIRFLOW_CTX_EXECUTION_DATE='2023-01-01T01:40:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2023-01-01T01:40:00+00:00'
[2024-06-29T21:36:55.140+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-29T21:36:55.194+0000] {logging_mixin.py:188} INFO - Error in generate_and_insert_data: Command '['python3', '/opt/airflow/generator/ecomm_generator.py']' returned non-zero exit status 1.
[2024-06-29T21:36:55.194+0000] {logging_mixin.py:188} INFO - stdout: 
[2024-06-29T21:36:55.194+0000] {logging_mixin.py:188} INFO - stderr: Traceback (most recent call last):
  File "/opt/airflow/generator/ecomm_generator.py", line 4, in <module>
    from faker import Faker
ModuleNotFoundError: No module named 'faker'
[2024-06-29T21:36:55.194+0000] {python.py:237} INFO - Done. Returned value was: None
[2024-06-29T21:36:55.195+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-29T21:36:55.199+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=ecomm_data_pipeline, task_id=generate_and_insert_data, run_id=scheduled__2023-01-01T01:40:00+00:00, execution_date=20230101T014000, start_date=20240629T213655, end_date=20240629T213655
[2024-06-29T21:36:55.237+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-29T21:36:55.244+0000] {taskinstance.py:3503} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-06-29T21:36:55.245+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-29T21:49:11.760+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-29T21:49:11.770+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: ecomm_data_pipeline.generate_and_insert_data scheduled__2023-01-01T01:40:00+00:00 [queued]>
[2024-06-29T21:49:11.773+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: ecomm_data_pipeline.generate_and_insert_data scheduled__2023-01-01T01:40:00+00:00 [queued]>
[2024-06-29T21:49:11.773+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 2
[2024-06-29T21:49:11.777+0000] {taskinstance.py:2330} INFO - Executing <Task(PythonOperator): generate_and_insert_data> on 2023-01-01 01:40:00+00:00
[2024-06-29T21:49:11.779+0000] {standard_task_runner.py:63} INFO - Started process 182 to run task
[2024-06-29T21:49:11.780+0000] {standard_task_runner.py:90} INFO - Running: ['airflow', 'tasks', 'run', 'ecomm_data_pipeline', 'generate_and_insert_data', 'scheduled__2023-01-01T01:40:00+00:00', '--job-id', '12', '--raw', '--subdir', 'DAGS_FOLDER/ecomm_dag.py', '--cfg-path', '/tmp/tmpyf5q4f9d']
[2024-06-29T21:49:11.780+0000] {standard_task_runner.py:91} INFO - Job 12: Subtask generate_and_insert_data
[2024-06-29T21:49:11.796+0000] {task_command.py:426} INFO - Running <TaskInstance: ecomm_data_pipeline.generate_and_insert_data scheduled__2023-01-01T01:40:00+00:00 [running]> on host 0b7af056b90c
[2024-06-29T21:49:11.823+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='ecomm_data_pipeline' AIRFLOW_CTX_TASK_ID='generate_and_insert_data' AIRFLOW_CTX_EXECUTION_DATE='2023-01-01T01:40:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2023-01-01T01:40:00+00:00'
[2024-06-29T21:49:11.823+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-29T21:49:11.879+0000] {logging_mixin.py:188} INFO - Error in generate_and_insert_data: Command '['python3', '/opt/airflow/generator/ecomm_generator.py']' returned non-zero exit status 1.
[2024-06-29T21:49:11.880+0000] {logging_mixin.py:188} INFO - stdout: 
[2024-06-29T21:49:11.880+0000] {logging_mixin.py:188} INFO - stderr: Traceback (most recent call last):
  File "/opt/airflow/generator/ecomm_generator.py", line 4, in <module>
    from faker import Faker
ModuleNotFoundError: No module named 'faker'
[2024-06-29T21:49:11.880+0000] {python.py:237} INFO - Done. Returned value was: None
[2024-06-29T21:49:11.880+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-29T21:49:11.885+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=ecomm_data_pipeline, task_id=generate_and_insert_data, run_id=scheduled__2023-01-01T01:40:00+00:00, execution_date=20230101T014000, start_date=20240629T214911, end_date=20240629T214911
[2024-06-29T21:49:11.928+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-29T21:49:11.935+0000] {taskinstance.py:3503} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-06-29T21:49:11.936+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-06-29T22:00:44.261+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-29T22:00:44.271+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: ecomm_data_pipeline.generate_and_insert_data scheduled__2023-01-01T01:40:00+00:00 [queued]>
[2024-06-29T22:00:44.273+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: ecomm_data_pipeline.generate_and_insert_data scheduled__2023-01-01T01:40:00+00:00 [queued]>
[2024-06-29T22:00:44.273+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 2
[2024-06-29T22:00:44.278+0000] {taskinstance.py:2330} INFO - Executing <Task(PythonOperator): generate_and_insert_data> on 2023-01-01 01:40:00+00:00
[2024-06-29T22:00:44.279+0000] {standard_task_runner.py:63} INFO - Started process 182 to run task
[2024-06-29T22:00:44.280+0000] {standard_task_runner.py:90} INFO - Running: ['airflow', 'tasks', 'run', 'ecomm_data_pipeline', 'generate_and_insert_data', 'scheduled__2023-01-01T01:40:00+00:00', '--job-id', '12', '--raw', '--subdir', 'DAGS_FOLDER/ecomm_dag.py', '--cfg-path', '/tmp/tmp08y4t9xm']
[2024-06-29T22:00:44.281+0000] {standard_task_runner.py:91} INFO - Job 12: Subtask generate_and_insert_data
[2024-06-29T22:00:44.298+0000] {task_command.py:426} INFO - Running <TaskInstance: ecomm_data_pipeline.generate_and_insert_data scheduled__2023-01-01T01:40:00+00:00 [running]> on host 799998b0d26e
[2024-06-29T22:00:44.326+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='ecomm_data_pipeline' AIRFLOW_CTX_TASK_ID='generate_and_insert_data' AIRFLOW_CTX_EXECUTION_DATE='2023-01-01T01:40:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2023-01-01T01:40:00+00:00'
[2024-06-29T22:00:44.326+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-29T22:00:44.380+0000] {logging_mixin.py:188} INFO - Error in generate_and_insert_data: Command '['python3', '/opt/airflow/generator/ecomm_generator.py']' returned non-zero exit status 1.
[2024-06-29T22:00:44.380+0000] {logging_mixin.py:188} INFO - stdout: 
[2024-06-29T22:00:44.380+0000] {logging_mixin.py:188} INFO - stderr: Traceback (most recent call last):
  File "/opt/airflow/generator/ecomm_generator.py", line 4, in <module>
    from faker import Faker
ModuleNotFoundError: No module named 'faker'
[2024-06-29T22:00:44.381+0000] {python.py:237} INFO - Done. Returned value was: None
[2024-06-29T22:00:44.381+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-29T22:00:44.385+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=ecomm_data_pipeline, task_id=generate_and_insert_data, run_id=scheduled__2023-01-01T01:40:00+00:00, execution_date=20230101T014000, start_date=20240629T220044, end_date=20240629T220044
[2024-06-29T22:00:44.425+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-29T22:00:44.432+0000] {taskinstance.py:3503} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-06-29T22:00:44.433+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
